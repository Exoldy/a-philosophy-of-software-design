# **Глава 20. Проектирование для производительности**

### **(Как сделать так, чтобы эта херня летала)**

До этого момента мы тут обсасывали тему сложности: как писать софт так, чтобы он был простым и понятным, как азбука. Но что, если ты пилишь систему, которая должна работать быстро? Как вопросы производительности должны влиять на архитектуру?

Спойлер: **Простота — это и есть скорость**. Сложный код обычно тормозит, потому что он делает кучу лишнего дерьма. Простой код ебашит прямо к цели.

## **20.1 Как вообще думать о производительности**

Первый вопрос: «Насколько сильно надо париться о скорости в процессе разработки?»

Тут есть два стула:
1.  **Задротство:** Ты пытаешься оптимизировать каждую строчку. Итог: разработка встает колом, код превращается в нечитаемую лапшу, а производительность не растет, потому что ты оптимизируешь не то.
2.  **Похуизм:** Ты кладешь болт на перформанс. Итог: «смерть от тысячи порезов». У тебя по всему коду размазаны мелкие тупняки. В итоге система работает в 5–10 раз медленнее, чем могла бы. И починить это потом невозможно, потому что нет одной «волшебной кнопки», чтобы всё ускорить.

**Правильный подход:** Используй мозг. Выбирай решения, которые «естественно эффективны», но остаются простыми. Главное — понимать, какие операции стоят **дорого**.

Вот тебе список вещей, которые сегодня стоят конских ресурсов (запиши на лбу):

*   **Сеть:** Даже внутри датацентра сгонять туда-обратно — это 10–50 мкс. Для процессора это вечность (десятки тысяч инструкций). А если лезешь через интернет — это вообще ледниковый период (10–100 мс).
*   **Диск (I/O):** Обычный HDD — это сраные миллионы инструкций простоя. SSD побыстрее, но тоже не фонтан.
*   **Выделение памяти (malloc/new):** Каждый раз, когда ты пишешь `new`, где-то плачет процессор. Аллокация, освобождение и, не дай бог, сборка мусора — это накладные расходы.
*   **Кэш-промахи (Cache misses):** Если процессору надо лезть в оперативку (RAM) за данными, он курит бамбук пару сотен тактов. Часто код тормозит не из-за вычислений, а тупо потому что данные разбросаны по памяти как попало.

---

Лучший способ узнать, что тормозит — гонять **микробенчмарки**. Не гадай, а замерь.
В проекте RAMCloud мы написали тулзу для этого. Потратили пару дней, зато теперь любой тест пишется за 5 минут.

Зная, что дорого, а что дешево, ты можешь выбирать правильные структуры данных.
*   Пример: Тебе надо хранить кучу объектов по ключу.
    *   Можно взять **Ordered Map** (дерево).
    *   Можно взять **Hash Table**.
    *   Оба варианта простые. Но хэш-таблица быстрее в 5–10 раз. Если тебе не нужен порядок элементов — бери хэш-таблицу и не выпендривайся.

*   Другой пример: Массив структур в C/C++.
    *   Вариант лоха: Массив указателей на структуры. Сначала выделяешь массив, потом каждую структуру отдельно. Память фрагментирована, кэш-промахи гарантированы.
    *   Вариант инженера: Массив самих структур. Один `malloc`, всё лежит плотненько, процессор доволен.

Иногда ради скорости приходится усложнять.
В RAMCloud нам нужна была минимальная задержка. Мы поняли, что стандартный сетевой стек ядра Linux — это тормозное болото. Мы **обошли ядро** и начали работать с сетевухой напрямую. Это добавило сложности, да. Но мы знали, что иначе никак. В остальных 99% случаев мы топили за простоту.

**Запомни:** Глубокие модули эффективнее мелких. Мелкие классы — это постоянные прыжки между слоями, а каждый прыжок — это оверхед.

## **20.2 Семь раз отмерь, один раз отрежь**

Допустим, ты всё сделал правильно, а система всё равно тормозит. Руки чешутся начать "оптимизировать" всё подряд? **Убери руки от клавиатуры!**

Твоя интуиция о том, где тормозит код — **говно**. Даже если ты сеньор-помидор. Ты начнешь ковырять места, которые вообще не влияют на общую картину, и только добавишь багов.

1.  **Сначала замерь.** Профилируй систему. Найди то самое узкое горлышко. Не "в целом всё медленно", а конкретно: "вот эта функция жрёт 80% времени".
2.  **Замерь "ДО" и "ПОСЛЕ".** Если ты что-то поменял, и оно не стало работать быстрее — откатывай изменения нахер. Не оставляй сложный код, если он не дает профита.

## **20.3 Проектирование вокруг критического пути**

Если ты нашел кусок кода, который реально тормозит всю систему, лучший способ это исправить — **фундаментальное изменение**. Смени алгоритм. Вкрути кэш.

Но если фундаментально менять нечего, придется заниматься микрохирургией. Это называется **"Designing around the critical path"** (Проектирование вокруг критического пути).

**Упражнение для мозга:**
Представь "Идеальный Код".
Забей на существующую структуру классов. Забей на все "правила приличия". Спроси себя: какой **минимальный** набор действий нужно выполнить процессору, чтобы решить задачу в самом частом (обычном) случае?
*   Выкинь все проверки ошибок.
*   Выкинь все спец-кейсы.
*   Представь, что все нужные данные лежат под рукой в одной куче.

Вот этот "Идеальный Код" — твоя цель. Теперь попробуй переписать реальный код так, чтобы он был максимально близок к этому идеалу, но при этом не выглядел как блевотина.

Главный враг скорости на критическом пути — **специальные случаи (special cases)**.
Каждый `if (isSpecialCase)` — это тормоз.
В идеале у тебя должна быть **одна** проверка в начале:
`if (всё_идет_по_плану) { ебашим_быстро(); } else { разбираемся_медленно(); }`

Код для "особых случаев" может быть медленным и красивым. Код для "критического пути" должен лететь как пуля.

## **20.4 Пример: Буферы в RAMCloud**

*Тут Оустерхаут рассказывает, как они ускорили класс Buffer в 2 раза.*

**Суть проблемы:**
Класс `Buffer` используется везде. Он позволяет хранить данные кусками (чанками), чтобы не копировать память лишний раз. Но старая реализация метода `alloc` (выделение места) была унылым говном.
Она проходила через кучу мелких методов-прокладок. Там было **6 (шесть, Карл!)** различных проверок условий в самом горячем месте кода. Проверяли, есть ли чанки, есть ли место, успешно ли выделилось... Скука смертная и тормоза.

**Решение:**
Они переписали всё нахер, ориентируясь на самый частый сценарий: "дописать данные в хвост последнего чанка".
Создали переменную `extraAppendBytes`, которая сразу говорит: "сколько места осталось".

**Новый алгоритм:**
1.  Проверяем `extraAppendBytes`. Если места хватает — просто двигаем указатель. Всё!
2.  Никаких лишних вызовов методов.
3.  Никаких лишних `if`-ов. Все пограничные случаи (нет чанков, чанк внешний, места нет) обрабатываются в ветке `else`.

**Результат:**
Код стал быстрее в 2 раза (с 8.8 нс до 4.75 нс).
Код стал **проще**. Убрали лишние слои абстракции.
Код стал короче на 20%.

## **20.5 Итог**

Главный урок этой главы: **Чистая архитектура и высокая скорость могут (и должны) спать в одной постели.**

Тот пример с буфером показал: ускорение в 2 раза, упрощение кода, уменьшение его объема.
Сложный код тормозит, потому что делает лишнюю работу.
Пиши просто. Скорее всего, твой простой код будет достаточно быстрым, и тебе вообще не придется заниматься всей этой херней с оптимизацией. Но если придется — ищи критический путь и вычищай с него всё лишнее, как грязь с ботинок.