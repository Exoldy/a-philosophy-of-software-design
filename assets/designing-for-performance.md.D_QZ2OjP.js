import{_ as t,o as r,c as e,ae as n}from"./chunks/framework.CM3gOIkZ.js";const d=JSON.parse('{"title":"20. Производительность (Performance)","description":"","frontmatter":{},"headers":[],"relativePath":"designing-for-performance.md","filePath":"designing-for-performance.md","lastUpdated":1769733417000}'),s={name:"designing-for-performance.md"};function a(l,o,i,g,p,c){return r(),e("div",null,[...o[0]||(o[0]=[n('<h1 id="_20-производительность-performance" tabindex="-1"><strong>20. Производительность (Performance)</strong> <a class="header-anchor" href="#_20-производительность-performance" aria-label="Permalink to &quot;**20. Производительность (Performance)**&quot;">​</a></h1><p><strong>(Чтобы не тормозило как жигули)</strong></p><p>До этого момента мы тут обсасывали тему сложности: как писать софт так, чтобы он был простым и понятным, как азбука. Но что, если ты пилишь систему, которая должна работать быстро? Как вопросы производительности должны влиять на архитектуру?</p><p>Спойлер: <strong>Простота — это и есть скорость</strong>. Сложный код обычно тормозит, потому что он делает кучу лишнего дерьма. Простой код ебашит прямо к цели.</p><h2 id="_20-1-как-вообще-думать-о-перформансе-не-оптимизируи-преждевременно-но-и-не-будь-тормозом" tabindex="-1"><strong>20.1 Как вообще думать о перформансе (Не оптимизируй преждевременно, но и не будь тормозом)</strong> <a class="header-anchor" href="#_20-1-как-вообще-думать-о-перформансе-не-оптимизируи-преждевременно-но-и-не-будь-тормозом" aria-label="Permalink to &quot;**20.1 Как вообще думать о перформансе (Не оптимизируй преждевременно, но и не будь тормозом)**&quot;">​</a></h2><p>Первый вопрос: «Насколько сильно надо париться о скорости в процессе разработки?»</p><p>Тут есть два стула:</p><ol><li><strong>Задротство:</strong> Ты пытаешься оптимизировать каждую строчку. Итог: разработка встает колом, код превращается в нечитаемую лапшу, а производительность не растет, потому что ты оптимизируешь не то.</li><li><strong>Похуизм:</strong> Ты кладешь болт на перформанс. Итог: «смерть от тысячи порезов». У тебя по всему коду размазаны мелкие тупняки. В итоге система работает в 5–10 раз медленнее, чем могла бы. И починить это потом невозможно, потому что нет одной «волшебной кнопки», чтобы всё ускорить.</li></ol><p><strong>Правильный подход:</strong> Используй мозг. Выбирай решения, которые «естественно эффективны», но остаются простыми. Главное — понимать, какие операции стоят <strong>дорого</strong>.</p><p>Вот тебе список вещей, которые сегодня стоят конских ресурсов (запиши на лбу):</p><ul><li><strong>Сеть:</strong> Даже внутри датацентра сгонять туда-обратно — это 10–50 мкс. Для процессора это вечность (десятки тысяч инструкций). А если лезешь через интернет — это вообще ледниковый период (10–100 мс).</li><li><strong>Диск (I/O):</strong> Обычный HDD — это сраные миллионы инструкций простоя. SSD побыстрее, но тоже не фонтан.</li><li><strong>Выделение памяти (malloc/new):</strong> Каждый раз, когда ты пишешь <code>new</code>, где-то плачет процессор. Аллокация, освобождение и, не дай бог, сборка мусора — это накладные расходы.</li><li><strong>Кэш-промахи (Cache misses):</strong> Если процессору надо лезть в оперативку (RAM) за данными, он курит бамбук пару сотен тактов. Часто код тормозит не из-за вычислений, а тупо потому что данные разбросаны по памяти как попало.</li></ul><hr><p>Лучший способ узнать, что тормозит — гонять <strong>микробенчмарки</strong>. Не гадай, а замерь. В проекте RAMCloud мы написали тулзу для этого. Потратили пару дней, зато теперь любой тест пишется за 5 минут.</p><p>Зная, что дорого, а что дешево, ты можешь выбирать правильные структуры данных.</p><ul><li><p>Пример: Тебе надо хранить кучу объектов по ключу.</p><ul><li>Можно взять <strong>Ordered Map</strong> (дерево).</li><li>Можно взять <strong>Hash Table</strong>.</li><li>Оба варианта простые. Но хэш-таблица быстрее в 5–10 раз. Если тебе не нужен порядок элементов — бери хэш-таблицу и не выпендривайся.</li></ul></li><li><p>Другой пример: Массив структур в C/C++.</p><ul><li>Вариант лоха: Массив указателей на структуры. Сначала выделяешь массив, потом каждую структуру отдельно. Память фрагментирована, кэш-промахи гарантированы.</li><li>Вариант инженера: Массив самих структур. Один <code>malloc</code>, всё лежит плотненько, процессор доволен.</li></ul></li></ul><p>Иногда ради скорости приходится усложнять. В RAMCloud нам нужна была минимальная задержка. Мы поняли, что стандартный сетевой стек ядра Linux — это тормозное болото. Мы <strong>обошли ядро</strong> и начали работать с сетевухой напрямую. Это добавило сложности, да. Но мы знали, что иначе никак. В остальных 99% случаев мы топили за простоту.</p><p><strong>Запомни:</strong> Глубокие модули эффективнее мелких. Мелкие классы — это постоянные прыжки между слоями, а каждый прыжок — это оверхед.</p><h2 id="_20-2-сначала-замерь-потом-меняи-measure-twice-cut-once" tabindex="-1"><strong>20.2 Сначала замерь, потом меняй (Measure twice, cut once)</strong> <a class="header-anchor" href="#_20-2-сначала-замерь-потом-меняи-measure-twice-cut-once" aria-label="Permalink to &quot;**20.2 Сначала замерь, потом меняй (Measure twice, cut once)**&quot;">​</a></h2><p>Допустим, ты всё сделал правильно, а система всё равно тормозит. Руки чешутся начать &quot;оптимизировать&quot; всё подряд? <strong>Убери руки от клавиатуры!</strong></p><p>Твоя интуиция о том, где тормозит код — <strong>говно</strong>. Даже если ты сеньор-помидор. Ты начнешь ковырять места, которые вообще не влияют на общую картину, и только добавишь багов.</p><ol><li><strong>Сначала замерь.</strong> Профилируй систему. Найди то самое узкое горлышко. Не &quot;в целом всё медленно&quot;, а конкретно: &quot;вот эта функция жрёт 80% времени&quot;.</li><li><strong>Замерь &quot;ДО&quot; и &quot;ПОСЛЕ&quot;.</strong> Если ты что-то поменял, и оно не стало работать быстрее — откатывай изменения нахер. Не оставляй сложный код, если он не дает профита.</li></ol><h2 id="_20-3-дизаин-вокруг-критического-пути-узкое-горлышко-бутылки" tabindex="-1"><strong>20.3 Дизайн вокруг критического пути (Узкое горлышко бутылки)</strong> <a class="header-anchor" href="#_20-3-дизаин-вокруг-критического-пути-узкое-горлышко-бутылки" aria-label="Permalink to &quot;**20.3 Дизайн вокруг критического пути (Узкое горлышко бутылки)**&quot;">​</a></h2><p>Если ты нашел кусок кода, который реально тормозит всю систему, лучший способ это исправить — <strong>фундаментальное изменение</strong>. Смени алгоритм. Вкрути кэш.</p><p>Но если фундаментально менять нечего, придется заниматься микрохирургией. Это называется <strong>&quot;Designing around the critical path&quot;</strong> (Проектирование вокруг критического пути).</p><p><strong>Упражнение для мозга:</strong> Представь &quot;Идеальный Код&quot;. Забей на существующую структуру классов. Забей на все &quot;правила приличия&quot;. Спроси себя: какой <strong>минимальный</strong> набор действий нужно выполнить процессору, чтобы решить задачу в самом частом (обычном) случае?</p><ul><li>Выкинь все проверки ошибок.</li><li>Выкинь все спец-кейсы.</li><li>Представь, что все нужные данные лежат под рукой в одной куче.</li></ul><p>Вот этот &quot;Идеальный Код&quot; — твоя цель. Теперь попробуй переписать реальный код так, чтобы он был максимально близок к этому идеалу, но при этом не выглядел как блевотина.</p><p>Главный враг скорости на критическом пути — <strong>специальные случаи (special cases)</strong>. Каждый <code>if (isSpecialCase)</code> — это тормоз. В идеале у тебя должна быть <strong>одна</strong> проверка в начале: <code>if (всё_идет_по_плану) { ебашим_быстро(); } else { разбираемся_медленно(); }</code></p><p>Код для &quot;особых случаев&quot; может быть медленным и красивым. Код для &quot;критического пути&quot; должен лететь как пуля.</p><h2 id="_20-4-пример-буфер-ramcloud" tabindex="-1"><strong>20.4 Пример: Буфер RAMCloud</strong> <a class="header-anchor" href="#_20-4-пример-буфер-ramcloud" aria-label="Permalink to &quot;**20.4 Пример: Буфер RAMCloud**&quot;">​</a></h2><p><em>Тут Оустерхаут рассказывает, как они ускорили класс Buffer в 2 раза.</em></p><p><strong>Суть проблемы:</strong> Класс <code>Buffer</code> используется везде. Он позволяет хранить данные кусками (чанками), чтобы не копировать память лишний раз. Но старая реализация метода <code>alloc</code> (выделение места) была унылым говном. Она проходила через кучу мелких методов-прокладок. Там было <strong>6 (шесть, Карл!)</strong> различных проверок условий в самом горячем месте кода. Проверяли, есть ли чанки, есть ли место, успешно ли выделилось... Скука смертная и тормоза.</p><p><strong>Решение:</strong> Они переписали всё нахер, ориентируясь на самый частый сценарий: &quot;дописать данные в хвост последнего чанка&quot;. Создали переменную <code>extraAppendBytes</code>, которая сразу говорит: &quot;сколько места осталось&quot;.</p><p><strong>Новый алгоритм:</strong></p><ol><li>Проверяем <code>extraAppendBytes</code>. Если места хватает — просто двигаем указатель. Всё!</li><li>Никаких лишних вызовов методов.</li><li>Никаких лишних <code>if</code>-ов. Все пограничные случаи (нет чанков, чанк внешний, места нет) обрабатываются в ветке <code>else</code>.</li></ol><p><strong>Результат:</strong> Код стал быстрее в 2 раза (с 8.8 нс до 4.75 нс). Код стал <strong>проще</strong>. Убрали лишние слои абстракции. Код стал короче на 20%.</p><h2 id="_20-5-итог" tabindex="-1"><strong>20.5 Итог</strong> <a class="header-anchor" href="#_20-5-итог" aria-label="Permalink to &quot;**20.5 Итог**&quot;">​</a></h2><p>Главный урок этой главы: <strong>Чистая архитектура и высокая скорость могут (и должны) спать в одной постели.</strong></p><p>Тот пример с буфером показал: ускорение в 2 раза, упрощение кода, уменьшение его объема. Сложный код тормозит, потому что делает лишнюю работу. Пиши просто. Скорее всего, твой простой код будет достаточно быстрым, и тебе вообще не придется заниматься всей этой херней с оптимизацией. Но если придется — ищи критический путь и вычищай с него всё лишнее, как грязь с ботинок.</p>',39)])])}const q=t(s,[["render",a]]);export{d as __pageData,q as default};
